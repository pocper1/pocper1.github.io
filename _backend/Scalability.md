---
title: Scalability
layout: collection
permalink: /backend/scalability/
collection: backend
category: backend
tags:
    - backend
    - scalability
---

---

你精心打造的應用上線了，初期運行良好。但隨著用戶量從 100 增長到 10,000，問題接踵而至：頁面加載越來越慢，數據庫頻繁超時，用戶開始抱怨。這就是典型的**可擴展性危機**。

這份指南將通過任務導向的方式，介紹解決這些問題的核心原則，幫助你構建一個從一開始就能夠平滑擴展的系統。

-   **目標讀者**: 遇到或擔心遇到性能瓶頸的開發者和架構師。
-   **你將學到**: 如何像大型互聯網公司一樣思考系統擴展性問題，並掌握對應的實戰策略。

---

## 策略一：別把所有雞蛋放同一個籃子——水平擴展

當一台伺服器不堪重負時，你有兩個選擇：

1.  **垂直擴展 (Scaling Up)**: 給這台伺服器升級，換上更強的 CPU、更大的內存。就像把你的小貨車換成一輛巨型卡車。

    -   **優點**: 簡單粗暴，立竿見影。
    -   **缺點**: 成本高昂，且總有物理極限。卡車再大，也有裝滿的時候，而且一旦卡車壞了，所有貨物都無法運送（單點故障）。

2.  **水平擴展 (Scaling Out)**: 增加更多普通配置的伺服器，組成一個集群。就像用一個由許多輛普通貨車組成的車隊來取代一輛大卡車。
    -   **優點**: 性價比高，彈性極佳，可以根據需要隨時增減貨車數量。一輛車壞了，其他車還能繼續工作（高可用性）。
    -   **缺點**: 需要一個“交通調度中心”（負載均衡器）來分配貨物，管理起來更複雜。

**實戰建議**: **優先選擇水平擴展**。這是現代雲原生應用的基石。你可以使用 AWS 的 Auto Scaling Group 或 Kubernetes 的 Horizontal Pod Autoscaler (HPA) 來自動化這個過程。

---

## 策略二：讓你的伺服器“失憶”——無狀態架構

**問題**: 如果你的伺服器上記錄了用戶的登錄狀態，那麼負載均衡器就必須確保同一個用戶的所有請求都發送到同一台伺服器。這就像指定某個包裹必須由固定的某一輛貨車運輸，大大降低了調度的靈活性。

**解決方案**: 讓伺服器本身不存儲任何會話（Session）狀態。所有處理請求所需的信息，要麼由客戶端在每次請求時提供，要麼存儲在一個所有伺服器都能訪問的外部共享存儲中。

-   **類比**: 每個包裹都貼上了完整的收件人地址和物品清單，任何一輛貨車拿到包裹都知道該怎麼處理，無需記住這個包裹之前的狀態。

**實戰方法**:

-   **使用 JWT (JSON Web Tokens)**: 用戶登錄後，伺服器發放一個包含用戶信息的加密 Token。客戶端在後續每個請求的 Header 中都帶上這個 Token。
-   **外部化 Session**: 將 Session 數據存儲在像 Redis 或 Memcached 這樣的集中式快取中。所有伺服器都從這裡讀取和寫入 Session 數據。

```python
# Flask 示例：使用 JWT 實現無狀態認證
from flask import Flask, request, jsonify
from flask_jwt_extended import create_access_token, jwt_required, JWTManager

app = Flask(__name__)
# 需要設置一個密鑰
app.config["JWT_SECRET_KEY"] = "your-super-secret-key"
jwt = JWTManager(app)

@app.route("/login", methods=["POST"])
def login():
    # 這裡簡化了用戶名密碼驗證
    username = request.json.get("username", None)
    access_token = create_access_token(identity=username)
    return jsonify(access_token=access_token)

@app.route("/profile")
@jwt_required()
def profile():
    # 因為請求中包含了 JWT，伺服器無需保存用戶狀態
    # 即可知道當前用戶是誰
    current_user = get_jwt_identity()
    return jsonify(logged_in_as=current_user)
```

---

## 策略三：分離讀寫壓力——數據庫擴展

數據庫往往是整個系統中最先達到瓶頸的地方。

### 1. 讀寫分離

**問題**: 在大多數應用中，“讀”操作的頻率遠高於“寫”操作（例如，瀏覽商品 vs. 下單）。如果所有請求都湧向同一個數據庫，讀取壓力會嚴重影響寫入性能。

**解決方案**: 設置一個主數據庫（Master）專門處理寫操作，並創建多個從數據庫（Replicas）來處理讀操作。主數據庫的數據會自動同步到所有從數據庫。

-   **實戰場景**: 一個新聞門戶網站，99% 的流量都是閱讀新聞。可以設置 1 台主數據庫和 10 台從數據庫，將所有讀請求分散到從數據庫上。
-   **注意事項**: 主從同步存在延遲。對於某些需要強一致性的讀操作（如剛下單後立即查看訂單詳情），可以強制從主數據庫讀取。

### 2. 數據庫分片 (Sharding)

**問題**: 當數據量達到億級甚至更高時，單個數據庫無論如何優化，其存儲和處理能力都將達到極限。

**解決方案**: 將數據水平拆分到多個獨立的數據庫實例中。這就像你不是把所有書籍都放在一個巨大的圖書館，而是按照類別（或首字母）分到多個不同的專業圖書館。

-   **分片策略**: 可以按用戶 ID 範圍、用戶地理位置、或對用戶 ID 進行哈希等方式來決定一條數據應該存儲在哪個分片。
-   **警告**: 分片是擴展數據庫的終極武器，但也是最複雜的。它會帶來跨分片查詢、分佈式事務、數據遷移等巨大挑戰。**除非萬不得已，不要輕易使用分片。**

---

## 策略四：別讓用戶等待——異步處理

**問題**: 用戶提交了一個請求，需要執行多個步驟，其中一些步驟非常耗時（如發送郵件、生成報表、處理圖片）。如果讓用戶一直等待所有步驟完成，體驗會非常糟糕。

**解決方案**: 使用消息佇列（Message Queue）將耗時任務異步化。

-   **工作流程**: Web 伺服器接收到請求後，只執行最核心、最快速的步驟（例如，在數據庫中創建一條“處理中”的記錄），然後立即返回“提交成功”的響應給用戶。同時，它將耗時的任務作為一個“消息”發送到消息佇列（如 RabbitMQ, Kafka）。後台會有專門的“工作者進程”（Worker）不斷地從佇列中取出消息並執行。

-   **實戰案例**: 影片上傳。Web 伺服器接收到影片後，立即返回上傳成功，並將“影片轉碼”任務放入消息佇列。用戶可以繼續瀏覽網站，而轉碼任務在後台默默進行。

---

## 策略五：把常用數據放在手邊——快取

**問題**: 很多數據是“讀多寫少”的，比如商品分類、用戶個人信息等。每次都從數據庫讀取這些數據，既慢又浪費資源。

**解決方案**: 將這些常用數據複製一份，存儲在速度更快的內存快取（In-Memory Cache）中，如 Redis。

-   **快取策略 (Cache-Aside Pattern)**:

    1.  應用程序請求數據時，首先檢查快取。
    2.  如果快取命中（Hit），直接返回數據。
    3.  如果快取未命中（Miss），則從數據庫讀取數據，將數據放入快取，然後返回。

-   **實戰案例**: 一個電商網站的商品詳情頁。商品標題、價格、描述等信息很少變動，非常適合快取。第一次訪問時從數據庫加載，後續成千上萬次的訪問都直接從 Redis 讀取，速度極快，同時也保護了數據庫。

-   **快取的挑戰**: 最大的挑戰是**快取一致性**。當數據庫中的數據更新時，如何確保快取中的數據也同步更新或失效？這需要精心設計快取失效策略。

---

## 總結：擴展性設計的思維模式

1.  **監控驅動**: 在猜測性能瓶頸之前，先用工具（如 Prometheus, Grafana）來監控和度量。數據會告訴你哪裡需要優化。
2.  **解耦與分離**: 按職責分離你的服務，讀寫分離、無狀態化、異步化都是這一思想的體現。
3.  **擁抱分佈式**: 認識到單機總有極限，從一開始就為水平擴展和分佈式部署做好準備。
4.  **漸進式架構**: 不要過早設計一個能應對十億用戶的系統。從一個簡單的架構開始，隨著業務增長，有針對性地、逐步地引入更複雜的擴展策略。
